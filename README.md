# Indian Sign Language Recognition using Deep Learning

## Overview

This project aims to develop an advanced recognition system for Indian Sign Language (ISL) using deep learning techniques, specifically leveraging Long Short-Term Memory (LSTM) networks with attention mechanisms. The goal is to enhance communication accessibility for the deaf and hard of hearing (HOH) community in India by automating the recognition of ISL gestures from video input.

## Features

-  **Attention-based LSTM Model**: Incorporates attention mechanisms to focus on relevant frames for improved gesture recognition.
-  **Real-time Gesture Recognition**: Optimized for real-time applications, suitable for mobile and embedded platforms.
-  **Robust Dataset**: A custom dataset of ISL gestures captured without external detection devices.

## Dataset

The dataset used for this project is available in the `dataset` folder. It consists of video samples of ISL gestures, with each gesture labeled accordingly.
